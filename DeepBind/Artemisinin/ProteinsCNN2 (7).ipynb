{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import Request, urlopen\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import glob\n",
    "from tensorboardX import SummaryWriter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epochs = 1\n",
    "uniprot_xs = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "#a = torch.cuda.FloatTensor(4, 4, 1) # create tensor on gpu\n",
    "#b = a.cpu() --- transfer a to cpu\n",
    "#c = b.numpy() --- turn into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['num_layers'] = []\n",
    "params['filter_sz'] = []\n",
    "params['num_filters'] = []\n",
    "params['learning_rate'] = []\n",
    "params['batch_sz'] = []\n",
    "params['epochs'] = []\n",
    "params['loss_last'] = []\n",
    "params['acc_last']= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_acc(pred, label):\n",
    "    l = loss_func(pred, label).cuda(1)\n",
    "    pr = pred.data.cpu().numpy()\n",
    "    la = label.data.cpu().numpy()\n",
    "    a = np.mean(np.equal(np.argmax(pr, 1), la))\n",
    "    return l, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(loss, testloss, acc, testacc, num):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    a = fig.add_subplot(121)\n",
    "    a.plot(loss)\n",
    "    a.plot(np.arange(len(testloss))*num, testloss)\n",
    "    a.set_xlabel('Training Iteration')\n",
    "    a.set_ylabel('Loss')\n",
    "    b = fig.add_subplot(122)\n",
    "    b.plot(acc)\n",
    "    b.plot(np.arange(len(testacc))*num, testacc)\n",
    "    b.set_xlabel('Training Iteration')\n",
    "    b.set_ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_param_dict(nl, fs, nf, lr, bs, ep):\n",
    "    params['num_layers'].append(nl)\n",
    "    params['filter_sz'].append(fs)\n",
    "    params['num_filters'].append(nf)\n",
    "    params['learning_rate'].append(lr)\n",
    "    params['batch_sz'].append(bs)\n",
    "    params['epochs'].append(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(x, y):\n",
    "    x = torch.from_numpy(x).cuda().float()\n",
    "    y = torch.from_numpy(y).cuda().long()\n",
    "    return Variable(x), Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniprot_data(kw, numxs):\n",
    "    '''Goes to the uniprot website and searches for \n",
    "       data with the keyword given. Returns the data \n",
    "       found up to limit elements.'''\n",
    "\n",
    "    kws = [kw, 'NOT+' + kw]\n",
    "    Protein_data = {}\n",
    "            \n",
    "    for i in range(2):\n",
    "        kw = kws[i]\n",
    "        url1 = 'http://www.uniprot.org/uniprot/?query='\n",
    "        url2 = '&columns=sequence&format=tab&limit='+str(numxs)\n",
    "        query_complete = url1 + kw + url2\n",
    "        request = Request(query_complete)\n",
    "        response = urlopen(request)\n",
    "        data = response.read()\n",
    "        data = str(data, 'utf-8')\n",
    "        data = data.split('\\n')\n",
    "        data = data[1:-1]\n",
    "        Protein_data[str(i)] = list(map(lambda x:x.lower(),data))\n",
    "\n",
    "    x = Protein_data['0'] + Protein_data['1']\n",
    "    y = np.zeros([numxs*2, ])\n",
    "    y[:numxs] = 1.\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_strings(c):\n",
    "    longest = len(max(c, key=len))\n",
    "    digits = len(str(longest))\n",
    "    pad_num = np.ceil(longest*10**(-(digits-2)))\n",
    "    pad_num = int(pad_num * 10**(digits-2))\n",
    "    N = len(c)\n",
    "    X = np.zeros([N, 1, pad_num, 1])\n",
    "    m = 0\n",
    "            \n",
    "    for seq in c:\n",
    "        x = [] \n",
    "        for letter in seq:\n",
    "            x.append(max(ord(letter)-97, 0))\n",
    "                    \n",
    "        x = np.asarray(x)\n",
    "        diff = pad_num - x.size\n",
    "\n",
    "        if diff % 2 == 0:\n",
    "            x = np.pad(x, diff//2, \n",
    "                        'constant', constant_values=22.)\n",
    "        else:\n",
    "            x = np.pad(x, (int(np.floor(diff/2)), \n",
    "                        int(np.ceil(diff/2))), \n",
    "                        'constant', constant_values=22.)\n",
    "        \n",
    "        X[m, ...] = x[None, :, None]\n",
    "        m += 1\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_layers, fsize, num_filters, str_shp):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model_ops = {}\n",
    "        self.n_layers = n_layers \n",
    "        ch = 1\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            if i % 2 == 0 and i > 0:\n",
    "                num_filters *= 2\n",
    "                \n",
    "            conv = nn.Conv2d(ch,\n",
    "                             num_filters,\n",
    "                             (1, fsize),\n",
    "                             padding=(0, int(np.floor(fsize/2)))).cuda()\n",
    "            self.model_ops['conv'+str(i)] = nn.DataParallel(conv)\n",
    "            ch = num_filters\n",
    "        self.fc1 = nn.DataParallel(nn.Linear(ch*str_shp*1, 2).cuda())\n",
    "        \n",
    "        \n",
    "    def forward(self, net):\n",
    "        for j in range(self.n_layers):\n",
    "            net = self.model_ops['conv'+str(j)](net)\n",
    "        net = net.view(net.shape[0], -1).cuda(1)\n",
    "        net = self.fc1(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull data from uniprot and make labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-090818e8fd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_uniprot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'homeobox'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniprot_xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'diff. nums of data & labels'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3e326d3f29ff>\u001b[0m in \u001b[0;36mget_uniprot_data\u001b[0;34m(kw, numxs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_complete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, Y = get_uniprot_data('homeobox', uniprot_xs)\n",
    "X = process_strings(X)\n",
    "X = np.transpose(X, (0, 3, 1, 2))\n",
    "assert(X.shape[0]==Y.shape[0]),'diff. nums of data & labels'\n",
    "\n",
    "# split data into training and testing\n",
    "train_num = int(0.8 * X.shape[0])\n",
    "testX = X[train_num:, ...]\n",
    "testY = Y[train_num:]\n",
    "X = X[:train_num, ...]\n",
    "Y = Y[:train_num]\n",
    "\n",
    "print('Train num: %d; Test num: %d'%(X.shape[0], testX.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(41):\n",
    "    # each iter use random point in parameter space\n",
    "    layers = int(np.random.randint(1, 8, 1)[0])\n",
    "    scale = np.random.uniform(0.1, 1.) / np.random.randint(1, 1000, 1)[0]\n",
    "    learning_rate = np.absolute(np.random.randn(1)[0]) * scale\n",
    "    batch_sz = np.around(np.random.randint(30, 170, 1)[0])\n",
    "    fsizes = int(np.random.randint(50, 500, 1)[0]) // layers\n",
    "    if fsizes % 2 == 0: fsizes += 1\n",
    "    nf = int(np.random.randint(10, 50, 1)[0])\n",
    "    epochs = int(np.random.randint(10, 51, 1)[0])\n",
    "    update_param_dict(layers, fsizes, nf, learning_rate,\n",
    "                      batch_sz, epochs)\n",
    "    print(params)\n",
    "    \n",
    "    # instantiate the network\n",
    "    Network = CNN(layers, fsizes, nf, X.shape[-1])\n",
    "    \n",
    "    # define loss function\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # define autodiff optimizer and initialize loss/acc lists\n",
    "    opt = optim.Adam(Network.parameters(), lr=learning_rate)\n",
    "    loss_ = []\n",
    "    acc_ = []\n",
    "    tloss_ = []\n",
    "    tacc_ = []\n",
    "    n_iters = int(np.ceil(X.shape[0] / batch_sz))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # shuffle data and labels\n",
    "        rand = np.random.permutation(X.shape[0])\n",
    "        X = X[rand, ...]\n",
    "        Y = Y[rand]\n",
    "        \n",
    "        for iters in range(X.shape[0]//batch_sz):\n",
    "            if batch_sz*(iters+1) < X.shape[0]:\n",
    "                x = X[iters*batch_sz:batch_sz*(iters+1), ...]\n",
    "                y = Y[iters*batch_sz:batch_sz*(iters+1)]\n",
    "            else:\n",
    "                x = X[iters*batch_sz:, ...]\n",
    "                y = Y[iters*batch_sz:]\n",
    "                \n",
    "            x, y = prepare_batch(x, y)\n",
    "        \n",
    "            # get the output of the network and compute loss/acc.\n",
    "            loss, acc = loss_acc(Network(x), y)\n",
    "            acc_.append(acc)\n",
    "            loss_.append(loss.data[0])\n",
    "            \n",
    "            # perform a step down the gradient\n",
    "            opt.zero_grad() # zero gradient\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            \n",
    "        # test on validation set and plot loss/acc\n",
    "        if epoch % test_epochs == 0:\n",
    "            randtest = np.random.randint(0, testX.shape[0], 700)\n",
    "            tx = testX[randtest, ...]\n",
    "            ty = testY[randtest]\n",
    "            tx, ty = prepare_batch(tx, ty)\n",
    "            test_loss, test_acc = loss_acc(Network(tx), ty)\n",
    "            tloss_.append(test_loss.data[0])\n",
    "            tacc_.append(test_acc) \n",
    "            \n",
    "    plot(loss_, tloss_, acc_, tacc_, n_iters)\n",
    "    tloss_ = np.mean(np.asarray(tloss_)[-8:])\n",
    "    tacc_ = np.mean(np.asarray(tacc_)[-8:])\n",
    "    params['loss_last'].append(tloss_)\n",
    "    params['acc_last'].append(tacc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('protein_hparams.pickle', 'wb') as handle:\n",
    "    pickle.dump(params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
